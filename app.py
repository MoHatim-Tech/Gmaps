import streamlit as st
import subprocess
import sys
import os
import time
import re
import requests
import asyncio
import io

# ÙˆØ¸ÙŠÙØ© Ù„ØªØ«Ø¨ÙŠØª Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø¨Ø±Ù…Ø¬ÙŠØ§Ù‹ Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©
def ensure_dependencies():
    try:
        import playwright
    except ImportError:
        subprocess.run([sys.executable, "-m", "pip", "install", "playwright"], check=True)
    try:
        import playwright_stealth
    except ImportError:
        subprocess.run([sys.executable, "-m", "pip", "install", "playwright-stealth"], check=True)
    try:
        import docx
    except ImportError:
        subprocess.run([sys.executable, "-m", "pip", "install", "python-docx"], check=True)

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Ù…Ø³ØªØ®Ø±Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø±Ø§Ø¦Ø· Ø¬ÙˆØ¬Ù„", layout="wide", initial_sidebar_state="expanded")

# ØªØµÙ…ÙŠÙ… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
style_code = """<link href="https://fonts.googleapis.com/css2?family=Tajawal:wght@400;500;700&display=swap" rel="stylesheet"><style>
    body, .stApp { font-family: 'Tajawal', sans-serif !important; direction: RTL !important; text-align: right !important; background-color: #F8FAFC !important; }
    [data-testid="stSidebar"] { background-color: #FFFFFF !important; border-left: 1px solid #E2E8F0 !important; }
    .stButton button { background-color: #2563EB !important; color: white !important; border-radius: 8px !important; width: 100% !important; font-weight: bold !important; border: none !important; }
    .developer-footer { position: fixed; bottom: 0; left: 0; width: 100%; background-color: #1E3A8A; color: white; text-align: center; padding: 8px 0; font-size: 0.9rem; z-index: 100; }
</style>"""
st.markdown(style_code, unsafe_allow_html=True)
st.markdown("""<div class="developer-footer">ğŸ‘¨â€ğŸ’» ØªØ·ÙˆÙŠØ±: <b>Ø¹Ø¨Ø¯Ø§Ù„Ù…Ù†Ø¹Ù… Ø­Ø§ØªÙ…</b> | ğŸ“: +966544451878 | ğŸ“§: info@mohatim.tech</div>""", unsafe_allow_html=True)

def extract_emails_from_url(url):
    try:
        if not url or url == "N/A": return "N/A"
        if not url.startswith('http'): url = 'https://' + url
        res = requests.get(url, timeout=5, headers={'User-Agent': 'Mozilla/5.0'})
        emails = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', res.text)
        valid = [e for e in emails if not any(x in e.lower() for x in ['png', 'jpg', 'wix', 'sentry'])]
        return ", ".join(list(set(valid))) if valid else "N/A"
    except: return "N/A"

def scrape_google_maps(search_query, max_results=10, data_placeholder=None, progress_bar=None):
    ensure_dependencies()
    from playwright.sync_api import sync_playwright
    from playwright_stealth import stealth_sync
    import pandas as pd
    
    with sync_playwright() as p:
        results = []
        try:
            browser = p.chromium.launch(headless=True, args=["--no-sandbox", "--disable-setuid-sandbox"])
            context = browser.new_context(user_agent="Mozilla/5.0", locale="ar-SA")
            page = context.new_page()
            stealth_sync(page)
            
            page.goto("https://www.google.com/maps?hl=ar", wait_until="networkidle")
            try:
                page.click('button:has-text("Ù‚Ø¨ÙˆÙ„"), button:has-text("ÙˆØ§ÙÙ‚")', timeout=5000)
            except: pass

            search_box = page.locator('#searchboxinput')
            search_box.wait_for(state="visible")
            for char in search_query:
                page.keyboard.type(char, delay=100)
            page.keyboard.press("Enter")
            
            time.sleep(10)
            
            seen_names = set()
            scroll_attempts = 0
            while len(results) < max_results and scroll_attempts < 30:
                items = page.locator('.hfpxzc, a[href*="/maps/place/"]').all()
                if not items:
                    page.mouse.wheel(0, 1000)
                    time.sleep(2)
                    scroll_attempts += 1
                    continue

                for item in items:
                    if len(results) >= max_results: break
                    try:
                        name = item.get_attribute("aria-label") or item.inner_text().split('\n')[0]
                        if not name or name in seen_names: continue
                        
                        item.click(force=True)
                        time.sleep(3)
                        
                        name_h1 = page.locator('h1.DUwDvf')
                        if name_h1.count() > 0:
                            actual_name = name_h1.first.inner_text()
                            if actual_name in seen_names: continue
                            
                            address = page.locator('button[data-item-id="address"]').first.inner_text() if page.locator('button[data-item-id="address"]').count() > 0 else "N/A"
                            phone = page.locator('button[data-item-id^="phone:tel:"]').first.inner_text() if page.locator('button[data-item-id^="phone:tel:"]').count() > 0 else "N/A"
                            website = page.locator('a[data-item-id="authority"]').first.get_attribute('href') if page.locator('a[data-item-id="authority"]').count() > 0 else "N/A"
                            
                            results.append({
                                "ğŸ¢ Ø§Ø³Ù… Ø§Ù„Ù…Ø¤Ø³Ø³Ø©": actual_name, "ğŸ“ Ø±Ù‚Ù… Ø§Ù„Ù‡Ø§ØªÙ": phone, "ğŸŒ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ": website,
                                "ğŸ“§ Ø§Ù„Ø§ÙŠÙ…ÙŠÙ„": extract_emails_from_url(website) if website != "N/A" else "N/A",
                                "ğŸ“ Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…ÙƒØªØ¨": address
                            })
                            seen_names.add(actual_name)
                            if progress_bar: progress_bar.progress(len(results) / max_results)
                            if data_placeholder: data_placeholder.dataframe(pd.DataFrame(results))
                    except: continue

                page.mouse.wheel(0, 3000)
                time.sleep(2)
                scroll_attempts += 1
            browser.close()
            return results
        except Exception as e:
            st.error(f"Ø®Ø·Ø£: {e}")
            return results

st.title("ğŸ” Ù†Ø¸Ø§Ù… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°ÙƒÙŠ")

with st.sidebar:
    st.markdown("### ğŸ› ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨Ø­Ø«")
    biz = st.text_input("Ù…Ø¬Ø§Ù„ Ø§Ù„Ù…Ø¤Ø³Ø³Ø©")
    city = st.text_input("Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©")
    country = st.text_input("Ø§Ù„Ø¯ÙˆÙ„Ø©")
    num = st.number_input("Ø§Ù„Ù†ØªØ§Ø¦Ø¬", 1, 100, 10)
    start = st.button("ğŸš€ Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬")

if start:
    if biz or city:
        query = f"{biz} ÙÙŠ {city} {country}".strip()
        st.info(f"ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: {query}")
        p_bar = st.progress(0); d_place = st.empty()
        final_data = scrape_google_maps(query, num, d_place, p_bar)
        if final_data:
            import pandas as pd
            from docx import Document
            from docx.shared import Pt
            from docx.enum.text import WD_ALIGN_PARAGRAPH
            
            st.success("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬!")
            df = pd.DataFrame(final_data)
            
            doc = Document()
            for entry in final_data:
                p = doc.add_paragraph()
                p.alignment = WD_ALIGN_PARAGRAPH.RIGHT
                p.add_run(f"ğŸ¢ Ø§Ù„Ù…Ø¤Ø³Ø³Ø©: {entry['ğŸ¢ Ø§Ø³Ù… Ø§Ù„Ù…Ø¤Ø³Ø³Ø©']}\n").bold = True
                p.add_run(f"ğŸ“ Ø§Ù„Ù‡Ø§ØªÙ: {entry['ğŸ“ Ø±Ù‚Ù… Ø§Ù„Ù‡Ø§ØªÙ']}\n")
                p.add_run(f"ğŸ“§ Ø§Ù„Ø§ÙŠÙ…ÙŠÙ„: {entry['ğŸ“§ Ø§Ù„Ø§ÙŠÙ…ÙŠÙ„']}\n")
                doc.add_paragraph("-" * 20)
            
            bio = io.BytesIO(); doc.save(bio)
            c1, c2 = st.columns(2)
            with c1: st.download_button("ØªØ­Ù…ÙŠÙ„ Word", bio.getvalue(), "results.docx")
            with c2: st.download_button("ØªØ­Ù…ÙŠÙ„ CSV", df.to_csv(index=False).encode('utf-8-sig'), "results.csv")
    else: st.warning("ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¨Ø­Ø«.")
