import streamlit as st
import pandas as pd
from playwright.sync_api import sync_playwright
import time
import re
import requests
from bs4 import BeautifulSoup
import asyncio
import sys
from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
import io

# Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© NotImplementedError Ø¹Ù„Ù‰ ÙˆÙŠÙ†Ø¯ÙˆØ²
if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

def extract_emails_from_url(url):
    try:
        if not url or url == "N/A": return "N/A"
        if not url.startswith('http'): url = 'https://' + url
        
        targets = [url]
        base_url = "/".join(url.split("/")[:3])
        potential_pages = ['contact', 'contact-us', 'about', 'about-us', 'support', 'terms']
        for page_name in potential_pages:
            targets.append(f"{base_url}/{page_name}")
            targets.append(f"{base_url}/ar/{page_name}")
            targets.append(f"{base_url}/en/{page_name}")
        
        targets = list(dict.fromkeys(targets))
        
        all_emails = set()
        for target in targets:
            try:
                response = requests.get(target, timeout=5, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'})
                if response.status_code == 200:
                    found = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', response.text)
                    for email in found:
                        if not any(ext in email.lower() for ext in ['.png', '.jpg', '.jpeg', '.gif', '.svg', 'wix', 'sentry']):
                            all_emails.add(email)
            except: continue
            if all_emails: break
            
        return ", ".join(list(all_emails)) if all_emails else "N/A"
    except:
        return "N/A"

def scrape_google_maps(search_query, max_results=10, data_placeholder=None, progress_bar=None):
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            locale="ar-SA",
            viewport={'width': 1920, 'height': 1080}
        )
        page = context.new_page()
        results = []
        
        try:
            page.goto(f"https://www.google.com/maps/search/{search_query}", wait_until="load", timeout=60000)
            time.sleep(5)
            
            try:
                if "consent" in page.url or page.locator('button[aria-label*="Accept all"]').count() > 0:
                    for selector in ['button[aria-label*="Accept all"]', 'button[aria-label*="ÙˆØ§ÙÙ‚"]', 'button[aria-label*="Ù‚Ø¨ÙˆÙ„"]', 'button:has-text("Accept all")']:
                        if page.locator(selector).count() > 0:
                            page.locator(selector).first.click()
                            page.wait_for_load_state("networkidle")
                            break
            except:
                pass

            seen_names = set()
            scroll_attempts = 0
            max_scroll_attempts = 30 
            
            while len(results) < max_results and scroll_attempts < max_scroll_attempts:
                item_selectors = ['a[href*="/maps/place/"]', '.hfpxzc', 'div[role="article"] a']
                items = []
                for sel in item_selectors:
                    found = page.locator(sel).all()
                    if len(found) > 0:
                        items = found
                        break
                
                if not items:
                    page.mouse.wheel(0, 2000)
                    time.sleep(3)
                    scroll_attempts += 1
                    continue

                for item in items:
                    if len(results) >= max_results: break
                    try:
                        card_name = item.get_attribute("aria-label") or item.inner_text().split('\n')[0]
                        if not card_name or card_name in seen_names or "N/A" in card_name: continue
                        
                        item.scroll_into_view_if_needed()
                        item.click(force=True)
                        time.sleep(3)
                        
                        name = "N/A"
                        name_selectors = ['h1.DUwDvf', 'h1.lfPIob', 'h1']
                        for selector in name_selectors:
                            if page.locator(selector).count() > 0:
                                name = page.locator(selector).first.inner_text()
                                break
                        
                        if name == "N/A" or name in seen_names: continue
                        seen_names.add(name)
                        
                        page_content = page.content()
                        emails_in_maps = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', page_content)
                        emails_in_maps = [e for e in emails_in_maps if not any(x in e.lower() for x in ['google', 'sentry', 'wix', 'example', 'domain', 'png', 'jpg'])]

                        address = "N/A"
                        address_loc = page.locator('button[data-item-id="address"]')
                        if address_loc.count() > 0: address = address_loc.first.inner_text()
                        
                        phone = "N/A"
                        phone_loc = page.locator('button[data-item-id^="phone:tel:"]')
                        if phone_loc.count() > 0: phone = phone_loc.first.inner_text()
                        
                        website = "N/A"
                        website_loc = page.locator('a[data-item-id="authority"]')
                        if website_loc.count() > 0: website = website_loc.first.get_attribute('href')
                        
                        email = "N/A"
                        if emails_in_maps: email = emails_in_maps[0]
                        elif website != "N/A": email = extract_emails_from_url(website)

                        new_entry = {
                            "ğŸ¢ Ø§Ø³Ù… Ø§Ù„Ù…Ø¤Ø³Ø³Ø©": name,
                            "ğŸ“ Ø±Ù‚Ù… Ø§Ù„Ù‡Ø§ØªÙ": phone,
                            "ğŸŒ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ": website,
                            "ğŸ“§ Ø§Ù„Ø§ÙŠÙ…ÙŠÙ„": email,
                            "ğŸ“ Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…ÙƒØªØ¨": address
                        }
                        results.append(new_entry)
                        
                        if progress_bar: progress_bar.progress(len(results) / max_results)
                        if data_placeholder: data_placeholder.dataframe(pd.DataFrame(results), use_container_width=True)
                    except: continue
                
                feed_selector = 'div[role="feed"]'
                if page.locator(feed_selector).count() > 0:
                    page.locator(feed_selector).evaluate("el => el.scrollBy(0, 2000)")
                else:
                    page.mouse.wheel(0, 2000)
                time.sleep(3)
                scroll_attempts += 1
                    
            browser.close()
            return results
        except Exception:
            if 'browser' in locals(): browser.close()
            return results

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
st.set_page_config(page_title="Ù…Ø³ØªØ®Ø±Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø±Ø§Ø¦Ø· Ø¬ÙˆØ¬Ù„", layout="wide", initial_sidebar_state="expanded")

# ØªØµÙ…ÙŠÙ… Ø¹ØµØ±ÙŠ Ù…ØªØ·ÙˆØ±
style_code = """
<link href="https://fonts.googleapis.com/css2?family=Tajawal:wght@300;400;500;700&display=swap" rel="stylesheet">
<style>
    /* Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© */
    * { font-family: 'Tajawal', sans-serif !important; }
    
    .stApp {
        background: linear-gradient(135deg, #f1f5f9 0%, #e2e8f0 100%) !important;
        direction: RTL !important;
        text-align: right !important;
    }

    /* Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ø²ÙˆØ§Ø¦Ø¯ */
    #MainMenu, footer, header { visibility: hidden !important; }
    
    /* Ø§Ù„Ø³Ø§ÙŠØ¯Ø¨Ø§Ø± Ø§Ù„Ø£Ù†ÙŠÙ‚ */
    [data-testid="stSidebar"] {
        background-color: rgba(255, 255, 255, 0.95) !important;
        backdrop-filter: blur(10px) !important;
        border-left: 1px solid rgba(30, 58, 138, 0.1) !important;
        box-shadow: -4px 0 15px rgba(0,0,0,0.05) !important;
    }

    /* Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª */
    .stTextInput input, .stNumberInput input {
        border-radius: 10px !important;
        border: 1px solid #cbd5e1 !important;
        padding: 12px !important;
        transition: all 0.3s ease !important;
    }

    .stTextInput input:focus {
        border-color: #2563eb !important;
        box-shadow: 0 0 0 2px rgba(37, 99, 235, 0.1) !important;
    }

    /* Ø£Ø²Ø±Ø§Ø± Ù…Ø°Ù‡Ù„Ø© */
    .stButton button {
        background: linear-gradient(90deg, #1e3a8a 0%, #2563eb 100%) !important;
        color: white !important;
        border: none !important;
        border-radius: 12px !important;
        padding: 20px !important;
        font-weight: 700 !important;
        font-size: 1.1rem !important;
        letter-spacing: 0.5px !important;
        transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275) !important;
        box-shadow: 0 4px 15px rgba(37, 99, 235, 0.2) !important;
    }

    .stButton button:hover {
        transform: scale(1.02) !important;
        box-shadow: 0 8px 25px rgba(37, 99, 235, 0.3) !important;
        background: linear-gradient(90deg, #2563eb 0%, #1e3a8a 100%) !important;
    }

    /* ÙƒØ±ÙˆØª Ø§Ù„Ù…Ø­ØªÙˆÙ‰ */
    .main-container {
        background: white !important;
        border-radius: 20px !important;
        padding: 30px !important;
        box-shadow: 0 10px 30px rgba(0,0,0,0.04) !important;
        border: 1px solid rgba(255,255,255,0.8) !important;
    }

    /* ØªØ®ØµÙŠØµ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª */
    [data-testid="stDataFrame"] {
        border: 1px solid #e2e8f0 !important;
        border-radius: 15px !important;
        overflow: hidden !important;
    }

    /* ØªØ°ÙŠÙŠÙ„ Ø§Ù„Ù…Ø·ÙˆØ± */
    .dev-footer {
        position: fixed;
        bottom: 0;
        left: 0;
        right: 0;
        background: rgba(30, 58, 138, 0.9);
        color: white;
        padding: 12px;
        text-align: center;
        backdrop-filter: blur(5px);
        font-weight: 500;
        z-index: 1000;
        font-size: 0.9rem;
    }

    /* Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† */
    h1 {
        background: linear-gradient(90deg, #1e3a8a, #3b82f6);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-weight: 800 !important;
        margin-bottom: 30px !important;
    }

    /* Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù… */
    .stProgress > div > div > div > div {
        background-color: #2563eb !important;
    }
</style>
"""
st.markdown(style_code, unsafe_allow_html=True)

# ØªØ°ÙŠÙŠÙ„ Ø§Ù„Ù…Ø·ÙˆØ±
st.markdown("""
    <div class="dev-footer">
        ğŸ‘¨â€ğŸ’» ØªØ·ÙˆÙŠØ±: <b>Ø¹Ø¨Ø¯Ø§Ù„Ù…Ù†Ø¹Ù… Ø­Ø§ØªÙ…</b> | ğŸ“: 0544451878 | ğŸ“§: info@mohatim.tech
    </div>
    """, unsafe_allow_html=True)

# Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø³Ø§ÙŠØ¯Ø¨Ø§Ø± (Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª)
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/854/854878.png", width=80)
    st.title("Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨Ø­Ø«")
    st.markdown("---")
    business_type = st.text_input("ğŸ¢ Ù…Ø¬Ø§Ù„ Ø§Ù„Ù…Ø¤Ø³Ø³Ø©", placeholder="Ù…Ø«Ø§Ù„: Ù…Ø·Ø§Ø¹Ù…ØŒ Ø´Ø±ÙƒØ§Øª ØªÙ‚Ù†ÙŠØ©")
    city = st.text_input("ğŸ“ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©", placeholder="Ø§Ù„Ø±ÙŠØ§Ø¶ØŒ Ø¬Ø¯Ø©")
    country = st.text_input("ğŸŒ Ø§Ù„Ø¯ÙˆÙ„Ø©", placeholder="Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©ØŒ Ù…ØµØ±")
    max_res = st.number_input("ğŸ”¢ Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", min_value=1, max_value=500, value=10)
    st.markdown("<br>", unsafe_allow_html=True)
    search_clicked = st.button("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬")

# Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
st.title("ğŸ” Ù†Ø¸Ø§Ù… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°ÙƒÙŠ")
st.info("Ù‚Ù… Ø¨ØªØ¹Ø¨Ø¦Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ø«Ù… Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± Ø§Ù„Ø¨Ø¯Ø¡.")

def create_word_doc(data):
    doc = Document()
    style = doc.styles['Normal']
    font = style.font
    font.name = 'Arial'
    font.size = Pt(12)
    doc.add_heading('Ù†ØªØ§Ø¦Ø¬ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø±Ø§Ø¦Ø· Ø¬ÙˆØ¬Ù„', 0).alignment = WD_ALIGN_PARAGRAPH.RIGHT
    for entry in data:
        p = doc.add_paragraph()
        p.alignment = WD_ALIGN_PARAGRAPH.RIGHT
        for key, val in entry.items():
            p.add_run(f"{key}: ").bold = True
            p.add_run(f"{val}\n")
        doc.add_paragraph("-" * 30).alignment = WD_ALIGN_PARAGRAPH.RIGHT
    doc.add_paragraph("\n")
    dev_info = doc.add_paragraph()
    dev_info.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = dev_info.add_run("ØªÙ… Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙˆØ§Ø³Ø·Ø© Ù†Ø¸Ø§Ù… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°ÙƒÙŠ")
    run.font.size = Pt(10)
    run.italic = True
    dev_contact = doc.add_paragraph()
    dev_contact.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run2 = dev_contact.add_run("ØªØ·ÙˆÙŠØ±: Ø¹Ø¨Ø¯Ø§Ù„Ù…Ù†Ø¹Ù… Ø­Ø§ØªÙ… | Ø¬ÙˆØ§Ù„: 0544451878 | Ø§ÙŠÙ…ÙŠÙ„: info@mohatim.tech")
    run2.font.size = Pt(10)
    run2.bold = True
    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()

if search_clicked:
    if business_type or city or country:
        query_parts = []
        if business_type: query_parts.append(business_type)
        location_parts = []
        if city: location_parts.append(city)
        if country: location_parts.append(country)
        if location_parts:
            query_parts.append("ÙÙŠ")
            query_parts.append(", ".join(location_parts))
        query = " ".join(query_parts)
        
        st.write(f"### ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ù€: {query}")
        progress_bar = st.progress(0)
        data_placeholder = st.empty()
        
        final_data = scrape_google_maps(query, max_res, data_placeholder, progress_bar)
        
        if final_data:
            st.success(f"âœ… Ø§ÙƒØªÙ…Ù„ Ø¨Ù†Ø¬Ø§Ø­! ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(final_data)} Ù…Ø¤Ø³Ø³Ø©.")
            df = pd.DataFrame(final_data)
            
            col_word, col_csv = st.columns(2)
            with col_word:
                word_data = create_word_doc(final_data)
                st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Word (.docx)", data=word_data, file_name="results.docx", use_container_width=True)
            with col_csv:
                csv = df.to_csv(index=False).encode('utf-8-sig')
                st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ CSV (.csv)", data=csv, file_name="results.csv", use_container_width=True)
        else:
            st.error("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬. Ø­Ø§ÙˆÙ„ ØªØºÙŠÙŠØ± Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø­Ø«.")
    else:
        st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù…Ø¹Ù„ÙˆÙ…Ø© ÙˆØ§Ø­Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ù„Ù„Ø¨Ø­Ø«.")
