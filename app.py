import streamlit as st
import pandas as pd
from playwright.sync_api import sync_playwright
from playwright_stealth import stealth_sync
import time
import re
import requests
from bs4 import BeautifulSoup
import asyncio
import sys
from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
import io
import subprocess

# ÙˆØ¸ÙŠÙØ© Ù„ØªØ«Ø¨ÙŠØª Ù…ØªØµÙØ­ Playwright ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ±ÙØ±
def install_playwright_browsers():
    try:
        subprocess.run(["playwright", "install", "chromium"], check=True)
    except Exception as e:
        st.error(f"Error installing browsers: {e}")

# ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ«Ø¨ÙŠØª Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
if 'playwright_installed' not in st.session_state:
    with st.spinner("Ø¬Ø§Ø±ÙŠ ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨Ø­Ø« (Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ø¯Ù‚ÙŠÙ‚Ø© ÙÙŠ Ø§Ù„Ù…Ø±Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰)..."):
        install_playwright_browsers()
        st.session_state['playwright_installed'] = True

# Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© NotImplementedError Ø¹Ù„Ù‰ ÙˆÙŠÙ†Ø¯ÙˆØ²
if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

def extract_emails_from_url(url):
    try:
        if not url or url == "N/A": return "N/A"
        if not url.startswith('http'): url = 'https://' + url
        targets = [url]
        base_url = "/".join(url.split("/")[:3])
        potential_pages = ['contact', 'contact-us', 'about', 'about-us', 'support']
        for page_name in potential_pages:
            targets.append(f"{base_url}/{page_name}")
        
        targets = list(dict.fromkeys(targets))
        all_emails = set()
        for target in targets:
            try:
                response = requests.get(target, timeout=5, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'})
                if response.status_code == 200:
                    found = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', response.text)
                    for email in found:
                        if not any(ext in email.lower() for ext in ['.png', '.jpg', '.jpeg', '.gif', '.svg', 'wix', 'sentry']):
                            all_emails.add(email)
            except: continue
            if all_emails: break
        return ", ".join(list(all_emails)) if all_emails else "N/A"
    except: return "N/A"

def scrape_google_maps(search_query, max_results=10, data_placeholder=None, progress_bar=None):
    with sync_playwright() as p:
        results = []
        try:
            browser = p.chromium.launch(headless=True, args=["--no-sandbox", "--disable-setuid-sandbox", "--disable-dev-shm-usage"])
            context = browser.new_context(
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
                viewport={'width': 1280, 'height': 720},
                locale="ar-SA"
            )
            page = context.new_page()
            stealth_sync(page)
            
            st.toast("ğŸŒ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®ÙˆØ§Ø¯Ù… Ø§Ù„Ø®Ø±Ø§Ø¦Ø·...")
            page.goto("https://www.google.com/maps?hl=ar", wait_until="networkidle", timeout=60000)
            
            try:
                page.click('button:has-text("Ù‚Ø¨ÙˆÙ„"), button:has-text("ÙˆØ§ÙÙ‚"), button:has-text("Accept")', timeout=5000)
                time.sleep(2)
            except: pass

            search_box = page.locator('#searchboxinput')
            search_box.wait_for(state="visible", timeout=20000)
            search_box.click()
            for char in search_query:
                page.keyboard.type(char, delay=150)
            page.keyboard.press("Enter")
            
            st.toast("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬...")
            time.sleep(10)

            # ØªØ´Ø®ÙŠØµ Ø§Ù„ÙØ´Ù„
            if page.locator('.Nv262d, .hfpxzc, h1.DUwDvf').count() == 0:
                st.session_state['debug_screenshot'] = page.screenshot()
            
            seen_names = set()
            scroll_attempts = 0
            
            while len(results) < max_results and scroll_attempts < 40:
                if page.locator('h1.DUwDvf').is_visible():
                    name = page.locator('h1.DUwDvf').inner_text()
                    if name not in seen_names:
                        address = page.locator('button[data-item-id="address"]').first.inner_text() if page.locator('button[data-item-id="address"]').count() > 0 else "N/A"
                        phone = page.locator('button[data-item-id^="phone:tel:"]').first.inner_text() if page.locator('button[data-item-id^="phone:tel:"]').count() > 0 else "N/A"
                        website = page.locator('a[data-item-id="authority"]').first.get_attribute('href') if page.locator('a[data-item-id="authority"]').count() > 0 else "N/A"
                        results.append({
                            "ğŸ¢ Ø§Ø³Ù… Ø§Ù„Ù…Ø¤Ø³Ø³Ø©": name, "ğŸ“ Ø±Ù‚Ù… Ø§Ù„Ù‡Ø§ØªÙ": phone, "ğŸŒ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ": website,
                            "ğŸ“§ Ø§Ù„Ø§ÙŠÙ…ÙŠÙ„": extract_emails_from_url(website) if website != "N/A" else "N/A",
                            "ğŸ“ Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…ÙƒØªØ¨": address
                        })
                        seen_names.add(name)
                        if data_placeholder: data_placeholder.dataframe(pd.DataFrame(results), use_container_width=True)
                        if max_results == 1: break

                items = page.locator('.hfpxzc, a[href*="/maps/place/"]').all()
                for item in items:
                    if len(results) >= max_results: break
                    try:
                        name = item.get_attribute("aria-label") or item.inner_text().split('\n')[0]
                        if not name or name in seen_names: continue
                        item.scroll_into_view_if_needed()
                        item.click(force=True)
                        time.sleep(3)
                        name_loc = page.locator('h1.DUwDvf')
                        if name_loc.count() > 0:
                            side_name = name_loc.first.inner_text()
                            if side_name in seen_names: continue
                            address = page.locator('button[data-item-id="address"]').first.inner_text() if page.locator('button[data-item-id="address"]').count() > 0 else "N/A"
                            phone = page.locator('button[data-item-id^="phone:tel:"]').first.inner_text() if page.locator('button[data-item-id^="phone:tel:"]').count() > 0 else "N/A"
                            website = page.locator('a[data-item-id="authority"]').first.get_attribute('href') if page.locator('a[data-item-id="authority"]').count() > 0 else "N/A"
                            results.append({
                                "ğŸ¢ Ø§Ø³Ù… Ø§Ù„Ù…Ø¤Ø³Ø³Ø©": side_name, "ğŸ“ Ø±Ù‚Ù… Ø§Ù„Ù‡Ø§ØªÙ": phone, "ğŸŒ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ": website,
                                "ğŸ“§ Ø§Ù„Ø§ÙŠÙ…ÙŠÙ„": extract_emails_from_url(website) if website != "N/A" else "N/A",
                                "ğŸ“ Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…ÙƒØªØ¨": address
                            })
                            seen_names.add(side_name)
                            if progress_bar: progress_bar.progress(len(results) / max_results)
                            if data_placeholder: data_placeholder.dataframe(pd.DataFrame(results), use_container_width=True)
                    except: continue

                page.mouse.wheel(0, 3000)
                time.sleep(2)
                scroll_attempts += 1
                if "Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©" in page.content() or "reached the end" in page.content(): break
            browser.close()
            return results
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙ†ÙŠ: {e}")
            if 'browser' in locals(): browser.close()
            return results

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
st.set_page_config(page_title="Ù…Ø³ØªØ®Ø±Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø±Ø§Ø¦Ø· Ø¬ÙˆØ¬Ù„", layout="wide", initial_sidebar_state="expanded")
style_code = """<link href="https://fonts.googleapis.com/css2?family=Tajawal:wght@400;500;700&display=swap" rel="stylesheet"><style>
    body, .stApp { font-family: 'Tajawal', sans-serif !important; direction: RTL !important; text-align: right !important; background-color: #F8FAFC !important; }
    h1, h2, h3, p, span, label { font-family: 'Tajawal', sans-serif !important; text-align: right !important; color: #1E3A8A !important; }
    [data-testid="stSidebar"] { background-color: #FFFFFF !important; border-left: 1px solid #E2E8F0 !important; }
    .stTextInput div[data-baseweb="input"], .stNumberInput div[data-baseweb="input"] { border: 1px solid #CBD5E1 !important; border-radius: 8px !important; }
    [data-testid="stDataFrame"], [data-testid="stTable"] { direction: LTR !important; text-align: left !important; background-color: white !important; border-radius: 12px !important; }
    .stButton button { background-color: #2563EB !important; color: white !important; border-radius: 8px !important; width: 100% !important; font-weight: bold !important; border: none !important; }
    .stButton button p { color: white !important; }
    .developer-footer { position: fixed; bottom: 0; left: 0; width: 100%; background-color: #1E3A8A; color: white; text-align: center; padding: 8px 0; font-family: 'Tajawal', sans-serif; z-index: 100; font-size: 0.9rem; }
</style>"""
st.markdown(style_code, unsafe_allow_html=True)

st.markdown("""<div class="developer-footer">ğŸ‘¨â€ğŸ’» ØªØ·ÙˆÙŠØ±: <b>Ø¹Ø¨Ø¯Ø§Ù„Ù…Ù†Ø¹Ù… Ø­Ø§ØªÙ…</b> | ğŸ“: +966544451878 | ğŸ“§: info@mohatim.tech</div>""", unsafe_allow_html=True)

st.title("ğŸ” Ù†Ø¸Ø§Ù… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°ÙƒÙŠ")

with st.sidebar:
    st.markdown("### ğŸ› ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨Ø­Ø«")
    business_type = st.text_input("Ù…Ø¬Ø§Ù„ Ø§Ù„Ù…Ø¤Ø³Ø³Ø©", placeholder="Ù…Ø·Ø§Ø¹Ù…ØŒ ÙÙ†Ø§Ø¯Ù‚...")
    city = st.text_input("Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©", placeholder="Ø§Ù„Ø±ÙŠØ§Ø¶ØŒ Ø¯Ø¨ÙŠ...")
    country = st.text_input("Ø§Ù„Ø¯ÙˆÙ„Ø©", placeholder="Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©...")
    max_res = st.number_input("Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©", min_value=1, max_value=500, value=10, step=1)
    st.markdown("---")
    search_clicked = st.button("ğŸš€ Ø§Ø¨Ø¯Ø£ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬")
    st.markdown("### ğŸ“– ØªØ¹Ù„ÙŠÙ…Ø§Øª")
    st.info("Ø£Ø¯Ø®Ù„ Ø§Ù„ØªÙØ§ØµÙŠÙ„ ÙˆØ§Ø¶ØºØ· Ø¨Ø¯Ø¡. Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ØŒ Ø³ÙŠØ¸Ù‡Ø± Ù‚Ø³Ù… ØªØ´Ø®ÙŠØµÙŠ ÙŠÙˆØ¶Ø­ Ø§Ù„Ø³Ø¨Ø¨.")

def create_word_doc(data):
    doc = Document()
    style = doc.styles['Normal']; font = style.font; font.name = 'Arial'; font.size = Pt(12)
    doc.add_heading('Ù†ØªØ§Ø¦Ø¬ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø±Ø§Ø¦Ø· Ø¬ÙˆØ¬Ù„', 0).alignment = WD_ALIGN_PARAGRAPH.RIGHT
    for entry in data:
        p = doc.add_paragraph(); p.alignment = WD_ALIGN_PARAGRAPH.RIGHT
        p.add_run(f"ğŸ¢ Ø§Ø³Ù… Ø§Ù„Ù…Ø¤Ø³Ø³Ø©: {entry['ğŸ¢ Ø§Ø³Ù… Ø§Ù„Ù…Ø¤Ø³Ø³Ø©']}\n").bold = True
        p.add_run(f"ğŸ“ Ø±Ù‚Ù… Ø§Ù„Ù‡Ø§ØªÙ: {entry['ğŸ“ Ø±Ù‚Ù… Ø§Ù„Ù‡Ø§ØªÙ']}\n")
        p.add_run(f"ğŸŒ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ: {entry['ğŸŒ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø§Ù„ÙƒØªØ±ÙˆÙ†ÙŠ']}\n")
        p.add_run(f"ğŸ“§ Ø§Ù„Ø§ÙŠÙ…ÙŠÙ„: {entry['ğŸ“§ Ø§Ù„Ø§ÙŠÙ…ÙŠÙ„']}\n")
        p.add_run(f"ğŸ“ Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…ÙƒØªØ¨: {entry['ğŸ“ Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù…ÙƒØªØ¨']}\n")
        doc.add_paragraph("-" * 30).alignment = WD_ALIGN_PARAGRAPH.RIGHT
    bio = io.BytesIO(); doc.save(bio); return bio.getvalue()

if search_clicked:
    if business_type or city or country:
        query = f"{business_type} ÙÙŠ {city} {country}".strip()
        st.info(f"ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: {query}")
        progress_bar = st.progress(0); data_placeholder = st.empty()
        
        final_data = scrape_google_maps(query, max_res, data_placeholder, progress_bar)
        
        if not final_data and 'debug_screenshot' in st.session_state:
            with st.expander("ğŸ› ï¸ ØªÙØ§ØµÙŠÙ„ ØªØ´Ø®ÙŠØµÙŠØ© (Ù„Ù…Ø§Ø°Ø§ Ù„Ù… ØªØ¸Ù‡Ø± Ù†ØªØ§Ø¦Ø¬ØŸ)"):
                st.image(st.session_state['debug_screenshot'])
                st.warning("Ø¥Ø°Ø§ Ø±Ø£ÙŠØª ØµÙˆØ± ÙƒØ§Ø¨ØªØ´Ø§ØŒ ÙÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù† Ø¬ÙˆØ¬Ù„ Ø­Ø¸Ø± Ø§Ù„Ø³ÙŠØ±ÙØ±. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø£Ùˆ ØºÙŠØ± ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¨Ø­Ø«.")
        
        if final_data:
            st.success("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬!")
            df = pd.DataFrame(final_data)
            c1, c2 = st.columns(2)
            with c1: st.download_button("ØªØ­Ù…ÙŠÙ„ Word", create_word_doc(final_data), "results.docx", use_container_width=True)
            with c2: st.download_button("ØªØ­Ù…ÙŠÙ„ CSV", df.to_csv(index=False).encode('utf-8-sig'), "results.csv", use_container_width=True)
    else: st.warning("ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù…Ø¹Ù„ÙˆÙ…Ø© Ø¨Ø­Ø« ÙˆØ§Ø­Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„.")
